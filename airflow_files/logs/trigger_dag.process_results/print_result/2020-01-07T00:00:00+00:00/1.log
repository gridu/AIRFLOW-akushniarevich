[2020-01-08 17:25:24,961] {taskinstance.py:630} INFO - Dependencies all met for <TaskInstance: trigger_dag.process_results.print_result 2020-01-07T00:00:00+00:00 [queued]>
[2020-01-08 17:25:25,162] {taskinstance.py:630} INFO - Dependencies all met for <TaskInstance: trigger_dag.process_results.print_result 2020-01-07T00:00:00+00:00 [queued]>
[2020-01-08 17:25:25,162] {taskinstance.py:841} INFO - 
--------------------------------------------------------------------------------
[2020-01-08 17:25:25,163] {taskinstance.py:842} INFO - Starting attempt 1 of 1
[2020-01-08 17:25:25,164] {taskinstance.py:843} INFO - 
--------------------------------------------------------------------------------
[2020-01-08 17:25:25,200] {taskinstance.py:862} INFO - Executing <Task(PythonOperator): print_result> on 2020-01-07T00:00:00+00:00
[2020-01-08 17:25:25,202] {base_task_runner.py:133} INFO - Running: ['airflow', 'run', 'trigger_dag.process_results', 'print_result', '2020-01-07T00:00:00+00:00', '--job_id', '63', '--pool', 'default_pool', '--raw', '-sd', 'DAGS_FOLDER/trigger_dag.py', '--cfg_path', '/tmp/tmpkpp59p4y']
[2020-01-08 17:25:27,264] {base_task_runner.py:115} INFO - Job 63: Subtask print_result /usr/local/lib/python3.7/site-packages/airflow/configuration.py:226: FutureWarning: The task_runner setting in [core] has the old default value of 'BashTaskRunner'. This value has been changed to 'StandardTaskRunner' in the running config, but please update your config before Apache Airflow 2.0.
[2020-01-08 17:25:27,265] {base_task_runner.py:115} INFO - Job 63: Subtask print_result   FutureWarning
[2020-01-08 17:25:27,265] {base_task_runner.py:115} INFO - Job 63: Subtask print_result /usr/local/lib/python3.7/site-packages/airflow/config_templates/airflow_local_settings.py:65: DeprecationWarning: The elasticsearch_host option in [elasticsearch] has been renamed to host - the old setting has been used, but please update your config.
[2020-01-08 17:25:27,266] {base_task_runner.py:115} INFO - Job 63: Subtask print_result   ELASTICSEARCH_HOST = conf.get('elasticsearch', 'HOST')
[2020-01-08 17:25:27,266] {base_task_runner.py:115} INFO - Job 63: Subtask print_result /usr/local/lib/python3.7/site-packages/airflow/config_templates/airflow_local_settings.py:67: DeprecationWarning: The elasticsearch_log_id_template option in [elasticsearch] has been renamed to log_id_template - the old setting has been used, but please update your config.
[2020-01-08 17:25:27,267] {base_task_runner.py:115} INFO - Job 63: Subtask print_result   ELASTICSEARCH_LOG_ID_TEMPLATE = conf.get('elasticsearch', 'LOG_ID_TEMPLATE')
[2020-01-08 17:25:27,268] {base_task_runner.py:115} INFO - Job 63: Subtask print_result /usr/local/lib/python3.7/site-packages/airflow/config_templates/airflow_local_settings.py:69: DeprecationWarning: The elasticsearch_end_of_log_mark option in [elasticsearch] has been renamed to end_of_log_mark - the old setting has been used, but please update your config.
[2020-01-08 17:25:27,270] {base_task_runner.py:115} INFO - Job 63: Subtask print_result   ELASTICSEARCH_END_OF_LOG_MARK = conf.get('elasticsearch', 'END_OF_LOG_MARK')
[2020-01-08 17:25:27,779] {base_task_runner.py:115} INFO - Job 63: Subtask print_result [2020-01-08 17:25:27,778] {settings.py:252} INFO - settings.configure_orm(): Using pool settings. pool_size=5, max_overflow=10, pool_recycle=1800, pid=374
[2020-01-08 17:25:29,662] {base_task_runner.py:115} INFO - Job 63: Subtask print_result [2020-01-08 17:25:29,659] {__init__.py:51} INFO - Using executor CeleryExecutor
[2020-01-08 17:25:29,687] {base_task_runner.py:115} INFO - Job 63: Subtask print_result [2020-01-08 17:25:29,685] {dagbag.py:92} INFO - Filling up the DagBag from /usr/local/airflow/dags/trigger_dag.py
[2020-01-08 17:25:30,316] {logging_mixin.py:112} INFO - [2020-01-08 17:25:30,316] {local_task_job.py:124} WARNING - Time since last heartbeat(0.26 s) < heartrate(5.0 s), sleeping for 4.743607 s
[2020-01-08 17:25:30,690] {base_task_runner.py:115} INFO - Job 63: Subtask print_result [2020-01-08 17:25:30,689] {cli.py:545} INFO - Running <TaskInstance: trigger_dag.process_results.print_result 2020-01-07T00:00:00+00:00 [running]> on host 6667999380fe
[2020-01-08 17:25:30,841] {python_operator.py:105} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_ID=trigger_dag.process_results
AIRFLOW_CTX_TASK_ID=print_result
AIRFLOW_CTX_EXECUTION_DATE=2020-01-07T00:00:00+00:00
AIRFLOW_CTX_DAG_RUN_ID=backfill_2020-01-07T00:00:00+00:00
[2020-01-08 17:25:30,876] {logging_mixin.py:112} INFO - [2020-01-08 17:25:30,876] {trigger_dag.py:21} INFO - trig__2020-01-07T00:00:00+00:00 ended
[2020-01-08 17:25:30,877] {logging_mixin.py:112} INFO - [2020-01-08 17:25:30,877] {trigger_dag.py:22} INFO - {'conf': <airflow.configuration.AirflowConfigParser object at 0x7f85ed7d05d0>, 'dag': <DAG: trigger_dag.process_results>, 'ds': '2020-01-07', 'next_ds': '2020-01-08', 'next_ds_nodash': '20200108', 'prev_ds': '2020-01-06', 'prev_ds_nodash': '20200106', 'ds_nodash': '20200107', 'ts': '2020-01-07T00:00:00+00:00', 'ts_nodash': '20200107T000000', 'ts_nodash_with_tz': '20200107T000000+0000', 'yesterday_ds': '2020-01-06', 'yesterday_ds_nodash': '20200106', 'tomorrow_ds': '2020-01-08', 'tomorrow_ds_nodash': '20200108', 'END_DATE': '2020-01-07', 'end_date': '2020-01-07', 'dag_run': <DagRun trigger_dag.process_results @ 2020-01-07 00:00:00+00:00: backfill_2020-01-07T00:00:00+00:00, externally triggered: False>, 'run_id': 'backfill_2020-01-07T00:00:00+00:00', 'execution_date': <Pendulum [2020-01-07T00:00:00+00:00]>, 'prev_execution_date': <Pendulum [2020-01-06T00:00:00+00:00]>, 'prev_execution_date_success': <Proxy at 0x7f85db745190 with factory <function TaskInstance.get_template_context.<locals>.<lambda> at 0x7f85db787c20>>, 'prev_start_date_success': <Proxy at 0x7f85db745230 with factory <function TaskInstance.get_template_context.<locals>.<lambda> at 0x7f85db739a70>>, 'next_execution_date': <Pendulum [2020-01-08T00:00:00+00:00]>, 'latest_date': '2020-01-07', 'macros': <module 'airflow.macros' from '/usr/local/lib/python3.7/site-packages/airflow/macros/__init__.py'>, 'params': {}, 'tables': None, 'task': <Task(PythonOperator): print_result>, 'task_instance': <TaskInstance: trigger_dag.process_results.print_result 2020-01-07T00:00:00+00:00 [running]>, 'ti': <TaskInstance: trigger_dag.process_results.print_result 2020-01-07T00:00:00+00:00 [running]>, 'task_instance_key_str': 'trigger_dag.process_results__print_result__20200107', 'test_mode': False, 'var': {'value': None, 'json': None}, 'inlets': [], 'outlets': [], 'templates_dict': None}
[2020-01-08 17:25:30,877] {python_operator.py:114} INFO - Done. Returned value was: None
[2020-01-08 17:25:35,067] {logging_mixin.py:112} INFO - [2020-01-08 17:25:35,066] {local_task_job.py:103} INFO - Task exited with return code 0
