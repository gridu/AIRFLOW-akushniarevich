[2020-01-08 19:17:36,429] {taskinstance.py:630} INFO - Dependencies all met for <TaskInstance: dag_id_0.insert_new_row 2020-01-08T19:16:15.069971+00:00 [queued]>
[2020-01-08 19:17:36,612] {taskinstance.py:630} INFO - Dependencies all met for <TaskInstance: dag_id_0.insert_new_row 2020-01-08T19:16:15.069971+00:00 [queued]>
[2020-01-08 19:17:36,613] {taskinstance.py:841} INFO - 
--------------------------------------------------------------------------------
[2020-01-08 19:17:36,614] {taskinstance.py:842} INFO - Starting attempt 1 of 1
[2020-01-08 19:17:36,615] {taskinstance.py:843} INFO - 
--------------------------------------------------------------------------------
[2020-01-08 19:17:36,714] {taskinstance.py:862} INFO - Executing <Task(PostgresOperator): insert_new_row> on 2020-01-08T19:16:15.069971+00:00
[2020-01-08 19:17:36,715] {base_task_runner.py:133} INFO - Running: ['airflow', 'run', 'dag_id_0', 'insert_new_row', '2020-01-08T19:16:15.069971+00:00', '--job_id', '104', '--pool', 'default_pool', '--raw', '-sd', 'DAGS_FOLDER/jobs_dag.py', '--cfg_path', '/tmp/tmp9do1309i']
[2020-01-08 19:17:38,103] {base_task_runner.py:115} INFO - Job 104: Subtask insert_new_row /usr/local/lib/python3.7/site-packages/airflow/configuration.py:226: FutureWarning: The task_runner setting in [core] has the old default value of 'BashTaskRunner'. This value has been changed to 'StandardTaskRunner' in the running config, but please update your config before Apache Airflow 2.0.
[2020-01-08 19:17:38,104] {base_task_runner.py:115} INFO - Job 104: Subtask insert_new_row   FutureWarning
[2020-01-08 19:17:38,105] {base_task_runner.py:115} INFO - Job 104: Subtask insert_new_row /usr/local/lib/python3.7/site-packages/airflow/config_templates/airflow_local_settings.py:65: DeprecationWarning: The elasticsearch_host option in [elasticsearch] has been renamed to host - the old setting has been used, but please update your config.
[2020-01-08 19:17:38,105] {base_task_runner.py:115} INFO - Job 104: Subtask insert_new_row   ELASTICSEARCH_HOST = conf.get('elasticsearch', 'HOST')
[2020-01-08 19:17:38,106] {base_task_runner.py:115} INFO - Job 104: Subtask insert_new_row /usr/local/lib/python3.7/site-packages/airflow/config_templates/airflow_local_settings.py:67: DeprecationWarning: The elasticsearch_log_id_template option in [elasticsearch] has been renamed to log_id_template - the old setting has been used, but please update your config.
[2020-01-08 19:17:38,106] {base_task_runner.py:115} INFO - Job 104: Subtask insert_new_row   ELASTICSEARCH_LOG_ID_TEMPLATE = conf.get('elasticsearch', 'LOG_ID_TEMPLATE')
[2020-01-08 19:17:38,107] {base_task_runner.py:115} INFO - Job 104: Subtask insert_new_row /usr/local/lib/python3.7/site-packages/airflow/config_templates/airflow_local_settings.py:69: DeprecationWarning: The elasticsearch_end_of_log_mark option in [elasticsearch] has been renamed to end_of_log_mark - the old setting has been used, but please update your config.
[2020-01-08 19:17:38,107] {base_task_runner.py:115} INFO - Job 104: Subtask insert_new_row   ELASTICSEARCH_END_OF_LOG_MARK = conf.get('elasticsearch', 'END_OF_LOG_MARK')
[2020-01-08 19:17:38,259] {base_task_runner.py:115} INFO - Job 104: Subtask insert_new_row [2020-01-08 19:17:38,259] {settings.py:252} INFO - settings.configure_orm(): Using pool settings. pool_size=5, max_overflow=10, pool_recycle=1800, pid=1862
[2020-01-08 19:17:38,816] {base_task_runner.py:115} INFO - Job 104: Subtask insert_new_row [2020-01-08 19:17:38,816] {__init__.py:51} INFO - Using executor CeleryExecutor
[2020-01-08 19:17:38,817] {base_task_runner.py:115} INFO - Job 104: Subtask insert_new_row [2020-01-08 19:17:38,816] {dagbag.py:92} INFO - Filling up the DagBag from /usr/local/airflow/dags/jobs_dag.py
[2020-01-08 19:17:38,999] {base_task_runner.py:115} INFO - Job 104: Subtask insert_new_row [2020-01-08 19:17:38,998] {cli.py:545} INFO - Running <TaskInstance: dag_id_0.insert_new_row 2020-01-08T19:16:15.069971+00:00 [running]> on host 6667999380fe
[2020-01-08 19:17:39,119] {postgres_operator.py:62} INFO - Executing: INSERT INTO clients VALUES(%s, '', %s)
[2020-01-08 19:17:39,145] {logging_mixin.py:112} INFO - [2020-01-08 19:17:39,145] {base_hook.py:84} INFO - Using connection to: id: postgres_default. Host: postgres, Port: 5432, Schema: airflow, Login: airflow, Password: XXXXXXXX, extra: {}
[2020-01-08 19:17:39,167] {logging_mixin.py:112} INFO - [2020-01-08 19:17:39,167] {dbapi_hook.py:168} INFO - INSERT INTO clients VALUES(%s, '', %s) with parameters (6738406, datetime.datetime(2020, 1, 8, 19, 17, 38, 880863))
[2020-01-08 19:17:41,332] {logging_mixin.py:112} INFO - [2020-01-08 19:17:41,332] {local_task_job.py:124} WARNING - Time since last heartbeat(0.11 s) < heartrate(5.0 s), sleeping for 4.887193 s
[2020-01-08 19:17:46,226] {logging_mixin.py:112} INFO - [2020-01-08 19:17:46,226] {local_task_job.py:103} INFO - Task exited with return code 0
