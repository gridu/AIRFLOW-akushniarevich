[2020-01-08 19:01:06,379] {taskinstance.py:630} INFO - Dependencies all met for <TaskInstance: dag_id_0.check_table_exist 2020-01-08T19:00:42.082277+00:00 [queued]>
[2020-01-08 19:01:06,440] {taskinstance.py:630} INFO - Dependencies all met for <TaskInstance: dag_id_0.check_table_exist 2020-01-08T19:00:42.082277+00:00 [queued]>
[2020-01-08 19:01:06,442] {taskinstance.py:841} INFO - 
--------------------------------------------------------------------------------
[2020-01-08 19:01:06,443] {taskinstance.py:842} INFO - Starting attempt 1 of 1
[2020-01-08 19:01:06,443] {taskinstance.py:843} INFO - 
--------------------------------------------------------------------------------
[2020-01-08 19:01:06,496] {taskinstance.py:862} INFO - Executing <Task(BranchPythonOperator): check_table_exist> on 2020-01-08T19:00:42.082277+00:00
[2020-01-08 19:01:06,497] {base_task_runner.py:133} INFO - Running: ['airflow', 'run', 'dag_id_0', 'check_table_exist', '2020-01-08T19:00:42.082277+00:00', '--job_id', '88', '--pool', 'default_pool', '--raw', '-sd', 'DAGS_FOLDER/jobs_dag.py', '--cfg_path', '/tmp/tmpsofwmuvl']
[2020-01-08 19:01:07,451] {base_task_runner.py:115} INFO - Job 88: Subtask check_table_exist /usr/local/lib/python3.7/site-packages/airflow/configuration.py:226: FutureWarning: The task_runner setting in [core] has the old default value of 'BashTaskRunner'. This value has been changed to 'StandardTaskRunner' in the running config, but please update your config before Apache Airflow 2.0.
[2020-01-08 19:01:07,451] {base_task_runner.py:115} INFO - Job 88: Subtask check_table_exist   FutureWarning
[2020-01-08 19:01:07,452] {base_task_runner.py:115} INFO - Job 88: Subtask check_table_exist /usr/local/lib/python3.7/site-packages/airflow/config_templates/airflow_local_settings.py:65: DeprecationWarning: The elasticsearch_host option in [elasticsearch] has been renamed to host - the old setting has been used, but please update your config.
[2020-01-08 19:01:07,452] {base_task_runner.py:115} INFO - Job 88: Subtask check_table_exist   ELASTICSEARCH_HOST = conf.get('elasticsearch', 'HOST')
[2020-01-08 19:01:07,452] {base_task_runner.py:115} INFO - Job 88: Subtask check_table_exist /usr/local/lib/python3.7/site-packages/airflow/config_templates/airflow_local_settings.py:67: DeprecationWarning: The elasticsearch_log_id_template option in [elasticsearch] has been renamed to log_id_template - the old setting has been used, but please update your config.
[2020-01-08 19:01:07,453] {base_task_runner.py:115} INFO - Job 88: Subtask check_table_exist   ELASTICSEARCH_LOG_ID_TEMPLATE = conf.get('elasticsearch', 'LOG_ID_TEMPLATE')
[2020-01-08 19:01:07,453] {base_task_runner.py:115} INFO - Job 88: Subtask check_table_exist /usr/local/lib/python3.7/site-packages/airflow/config_templates/airflow_local_settings.py:69: DeprecationWarning: The elasticsearch_end_of_log_mark option in [elasticsearch] has been renamed to end_of_log_mark - the old setting has been used, but please update your config.
[2020-01-08 19:01:07,454] {base_task_runner.py:115} INFO - Job 88: Subtask check_table_exist   ELASTICSEARCH_END_OF_LOG_MARK = conf.get('elasticsearch', 'END_OF_LOG_MARK')
[2020-01-08 19:01:07,570] {base_task_runner.py:115} INFO - Job 88: Subtask check_table_exist [2020-01-08 19:01:07,569] {settings.py:252} INFO - settings.configure_orm(): Using pool settings. pool_size=5, max_overflow=10, pool_recycle=1800, pid=1580
[2020-01-08 19:01:08,436] {base_task_runner.py:115} INFO - Job 88: Subtask check_table_exist [2020-01-08 19:01:08,435] {__init__.py:51} INFO - Using executor CeleryExecutor
[2020-01-08 19:01:08,437] {base_task_runner.py:115} INFO - Job 88: Subtask check_table_exist [2020-01-08 19:01:08,436] {dagbag.py:92} INFO - Filling up the DagBag from /usr/local/airflow/dags/jobs_dag.py
[2020-01-08 19:01:08,582] {base_task_runner.py:115} INFO - Job 88: Subtask check_table_exist [2020-01-08 19:01:08,582] {cli.py:545} INFO - Running <TaskInstance: dag_id_0.check_table_exist 2020-01-08T19:00:42.082277+00:00 [running]> on host 125293df2c01
[2020-01-08 19:01:08,659] {python_operator.py:105} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_ID=dag_id_0
AIRFLOW_CTX_TASK_ID=check_table_exist
AIRFLOW_CTX_EXECUTION_DATE=2020-01-08T19:00:42.082277+00:00
AIRFLOW_CTX_DAG_RUN_ID=manual__2020-01-08T19:00:42.082277+00:00
[2020-01-08 19:01:08,685] {logging_mixin.py:112} INFO - [2020-01-08 19:01:08,685] {base_hook.py:84} INFO - Using connection to: id: postgres_default. Host: postgres, Port: None, Schema: airflow, Login: postgres, Password: XXXXXXXX, extra: {}
[2020-01-08 19:01:08,706] {taskinstance.py:1058} ERROR - FATAL:  password authentication failed for user "postgres"
Traceback (most recent call last):
  File "/usr/local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 930, in _run_raw_task
    result = task_copy.execute(context=context)
  File "/usr/local/lib/python3.7/site-packages/airflow/operators/python_operator.py", line 141, in execute
    branch = super(BranchPythonOperator, self).execute(context)
  File "/usr/local/lib/python3.7/site-packages/airflow/operators/python_operator.py", line 113, in execute
    return_value = self.execute_callable()
  File "/usr/local/lib/python3.7/site-packages/airflow/operators/python_operator.py", line 118, in execute_callable
    return self.python_callable(*self.op_args, **self.op_kwargs)
  File "/usr/local/airflow/dags/jobs_dag.py", line 30, in check_table_existance
    query = hook.get_records(sql=sql_to_get_schema)
  File "/usr/local/lib/python3.7/site-packages/airflow/hooks/dbapi_hook.py", line 112, in get_records
    with closing(self.get_conn()) as conn:
  File "/usr/local/lib/python3.7/site-packages/airflow/hooks/postgres_hook.py", line 76, in get_conn
    self.conn = psycopg2.connect(**conn_args)
  File "/usr/local/airflow/.local/lib/python3.7/site-packages/psycopg2/__init__.py", line 126, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: FATAL:  password authentication failed for user "postgres"

[2020-01-08 19:01:08,714] {taskinstance.py:1089} INFO - Marking task as FAILED.
[2020-01-08 19:01:08,811] {base_task_runner.py:115} INFO - Job 88: Subtask check_table_exist Traceback (most recent call last):
[2020-01-08 19:01:08,816] {base_task_runner.py:115} INFO - Job 88: Subtask check_table_exist   File "/usr/local/bin/airflow", line 37, in <module>
[2020-01-08 19:01:08,819] {base_task_runner.py:115} INFO - Job 88: Subtask check_table_exist     args.func(args)
[2020-01-08 19:01:08,826] {base_task_runner.py:115} INFO - Job 88: Subtask check_table_exist   File "/usr/local/lib/python3.7/site-packages/airflow/utils/cli.py", line 74, in wrapper
[2020-01-08 19:01:08,827] {base_task_runner.py:115} INFO - Job 88: Subtask check_table_exist     return f(*args, **kwargs)
[2020-01-08 19:01:08,830] {base_task_runner.py:115} INFO - Job 88: Subtask check_table_exist   File "/usr/local/lib/python3.7/site-packages/airflow/bin/cli.py", line 551, in run
[2020-01-08 19:01:08,832] {base_task_runner.py:115} INFO - Job 88: Subtask check_table_exist     _run(args, dag, ti)
[2020-01-08 19:01:08,833] {base_task_runner.py:115} INFO - Job 88: Subtask check_table_exist   File "/usr/local/lib/python3.7/site-packages/airflow/bin/cli.py", line 469, in _run
[2020-01-08 19:01:08,833] {base_task_runner.py:115} INFO - Job 88: Subtask check_table_exist     pool=args.pool,
[2020-01-08 19:01:08,834] {base_task_runner.py:115} INFO - Job 88: Subtask check_table_exist   File "/usr/local/lib/python3.7/site-packages/airflow/utils/db.py", line 74, in wrapper
[2020-01-08 19:01:08,835] {base_task_runner.py:115} INFO - Job 88: Subtask check_table_exist     return func(*args, **kwargs)
[2020-01-08 19:01:08,836] {base_task_runner.py:115} INFO - Job 88: Subtask check_table_exist   File "/usr/local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 930, in _run_raw_task
[2020-01-08 19:01:08,837] {base_task_runner.py:115} INFO - Job 88: Subtask check_table_exist     result = task_copy.execute(context=context)
[2020-01-08 19:01:08,838] {base_task_runner.py:115} INFO - Job 88: Subtask check_table_exist   File "/usr/local/lib/python3.7/site-packages/airflow/operators/python_operator.py", line 141, in execute
[2020-01-08 19:01:08,839] {base_task_runner.py:115} INFO - Job 88: Subtask check_table_exist     branch = super(BranchPythonOperator, self).execute(context)
[2020-01-08 19:01:08,840] {base_task_runner.py:115} INFO - Job 88: Subtask check_table_exist   File "/usr/local/lib/python3.7/site-packages/airflow/operators/python_operator.py", line 113, in execute
[2020-01-08 19:01:08,841] {base_task_runner.py:115} INFO - Job 88: Subtask check_table_exist     return_value = self.execute_callable()
[2020-01-08 19:01:08,850] {base_task_runner.py:115} INFO - Job 88: Subtask check_table_exist   File "/usr/local/lib/python3.7/site-packages/airflow/operators/python_operator.py", line 118, in execute_callable
[2020-01-08 19:01:08,851] {base_task_runner.py:115} INFO - Job 88: Subtask check_table_exist     return self.python_callable(*self.op_args, **self.op_kwargs)
[2020-01-08 19:01:08,852] {base_task_runner.py:115} INFO - Job 88: Subtask check_table_exist   File "/usr/local/airflow/dags/jobs_dag.py", line 30, in check_table_existance
[2020-01-08 19:01:08,853] {base_task_runner.py:115} INFO - Job 88: Subtask check_table_exist     query = hook.get_records(sql=sql_to_get_schema)
[2020-01-08 19:01:08,854] {base_task_runner.py:115} INFO - Job 88: Subtask check_table_exist   File "/usr/local/lib/python3.7/site-packages/airflow/hooks/dbapi_hook.py", line 112, in get_records
[2020-01-08 19:01:08,856] {base_task_runner.py:115} INFO - Job 88: Subtask check_table_exist     with closing(self.get_conn()) as conn:
[2020-01-08 19:01:08,858] {base_task_runner.py:115} INFO - Job 88: Subtask check_table_exist   File "/usr/local/lib/python3.7/site-packages/airflow/hooks/postgres_hook.py", line 76, in get_conn
[2020-01-08 19:01:08,860] {base_task_runner.py:115} INFO - Job 88: Subtask check_table_exist     self.conn = psycopg2.connect(**conn_args)
[2020-01-08 19:01:08,862] {base_task_runner.py:115} INFO - Job 88: Subtask check_table_exist   File "/usr/local/airflow/.local/lib/python3.7/site-packages/psycopg2/__init__.py", line 126, in connect
[2020-01-08 19:01:08,864] {base_task_runner.py:115} INFO - Job 88: Subtask check_table_exist     conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
[2020-01-08 19:01:08,865] {base_task_runner.py:115} INFO - Job 88: Subtask check_table_exist psycopg2.OperationalError: FATAL:  password authentication failed for user "postgres"
[2020-01-08 19:01:08,866] {base_task_runner.py:115} INFO - Job 88: Subtask check_table_exist 
[2020-01-08 19:01:11,346] {logging_mixin.py:112} INFO - [2020-01-08 19:01:11,346] {local_task_job.py:124} WARNING - Time since last heartbeat(0.05 s) < heartrate(5.0 s), sleeping for 4.946796 s
[2020-01-08 19:01:16,296] {logging_mixin.py:112} INFO - [2020-01-08 19:01:16,296] {local_task_job.py:103} INFO - Task exited with return code 1
